{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarioZZJ/data/blob/master/onclp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0QCgBMbX1X5",
        "outputId": "ee4f8738-7ece-4fd2-a0b7-5d54d268b215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KguGW7KuX_7z"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/dataset.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_sPYTsNZKg5",
        "outputId": "fb04f11d-0855-4aa0-cdf6-f480fcbba87b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.15)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910476 sha256=bb0e0823c102f550655b8c3886e75e457aa57e50ccf2827024925006ed8150e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10DjOwBXxaPw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import InMemoryDataset,Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch_geometric.utils import negative_sampling\n",
        "import numpy as np\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36U8p-dnB12M"
      },
      "outputs": [],
      "source": [
        "def make_deterministic(random_seed = 711):\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "make_deterministic(711)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3iSMi3Qxy57"
      },
      "outputs": [],
      "source": [
        "class OncologyMeSH(InMemoryDataset):\n",
        "    def __init__(self, root, year,transform=None, pre_transform=None):\n",
        "        self.year = year\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return [f'oncology{self.year}.pt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOXwHfkeYdGm"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0, path='checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        Early stopping 定义\n",
        "        \n",
        "        :param patience: 当验证集损失连续多少轮没有下降时停止训练\n",
        "        :param delta: 验证集损失的最小变化，当变化小于 delta 时认为模型没有明显提升\n",
        "        :param path: 记录模型权重的文件路径\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.counter = 0  # 记录验证集损失连续没有下降的轮数\n",
        "        self.best_score = None  # 记录最佳验证集损失\n",
        "        self.early_stop = False  # 是否停止训练\n",
        "        self.val_loss_min = np.Inf  # 记录最小验证集损失\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        \"\"\"\n",
        "        Early stopping 逻辑\n",
        "\n",
        "        :param val_loss: 当前轮次验证集损失\n",
        "        :param model: 当前轮次模型\n",
        "        :return: 如果需要停止训练，返回 True；否则返回 False\n",
        "        \"\"\"\n",
        "        if self.best_score is None:\n",
        "            self.best_score = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif val_loss > self.best_score - self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        \"\"\"\n",
        "        保存模型权重\n",
        "\n",
        "        :param val_loss: 当前轮次验证集损失\n",
        "        :param model: 当前轮次模型\n",
        "        \"\"\"\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-6xooJHyiID"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score, recall_score\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "\n",
        "def train_link_predictor(\n",
        "    model, train_data, val_data, optimizer, criterion, n_epochs=200, patience=20, delta=0.0003, ckp_path='checkpoint.pt'\n",
        "):\n",
        "    early_stopping = EarlyStopping(patience=patience, delta=delta, path=ckp_path)\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        z = model.encode(train_data.x, train_data.edge_index)\n",
        "\n",
        "        # sampling training negatives for every training epoch\n",
        "        neg_edge_index = negative_sampling(\n",
        "            edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
        "            num_neg_samples=train_data.edge_label_index.size(1), method='sparse',force_undirected=True)\n",
        "\n",
        "        edge_label_index = torch.cat(\n",
        "            [train_data.edge_label_index, neg_edge_index],\n",
        "            dim=-1,\n",
        "        )\n",
        "        edge_label = torch.cat([\n",
        "            train_data.edge_label,\n",
        "            train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
        "        ], dim=0)\n",
        "\n",
        "        out = model.decode(z, edge_label_index).view(-1)\n",
        "        loss = criterion(out, edge_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # val_auc = eval_link_predictor(model, val_data)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            z = model.encode(val_data.x, val_data.edge_index)\n",
        "            out = model.decode(z, val_data.edge_label_index).view(-1).sigmoid()\n",
        "            val_loss = criterion(out, val_data.edge_label)\n",
        "        val_auc = roc_auc_score(val_data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
        "\n",
        "        if early_stopping(val_loss, model):\n",
        "            break\n",
        "\n",
        "        # if epoch % 1 == 0:\n",
        "            # print(f\"Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_link_predictor(model, data):\n",
        "\n",
        "    model.eval()\n",
        "    z = model.encode(data.x, data.edge_index)\n",
        "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
        "\n",
        "    return [roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy()),\n",
        "            f1_score(data.edge_label.cpu().numpy(), out.cpu().numpy() > 0.5),\n",
        "            accuracy_score(data.edge_label.cpu().numpy(), out.cpu().numpy() > 0.5),\n",
        "            precision_score(data.edge_label.cpu().numpy(), out.cpu().numpy() > 0.5),\n",
        "            recall_score(data.edge_label.cpu().numpy(), out.cpu().numpy() > 0.5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL8J70DFyqdU"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "    def decode(self, z, edge_label_index):\n",
        "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(\n",
        "            dim=-1\n",
        "        )  # product of a pair of nodes on each edge\n",
        "\n",
        "    def decode_all(self, z):\n",
        "        prob_adj = z @ z.t()\n",
        "        return (prob_adj > 0).nonzero(as_tuple=False).t()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vmTrYQcyuMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0428c34-01ac-4c39-e180-1b781165f29a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2002 | [MeSH] AUC-0.9221 F1-0.7738 ; [Eyes] AUC-0.9049 F1-0.7443 .\n",
            "2003 | [MeSH] AUC-0.9192 F1-0.7701 ; [Eyes] AUC-0.9046 F1-0.7426 .\n",
            "2004 | [MeSH] AUC-0.9337 F1-0.7799 ; [Eyes] AUC-0.9105 F1-0.7401 .\n",
            "2005 | [MeSH] AUC-0.9332 F1-0.7761 ; [Eyes] AUC-0.9152 F1-0.7362 .\n",
            "2006 | [MeSH] AUC-0.9247 F1-0.7687 ; [Eyes] AUC-0.9146 F1-0.7304 .\n",
            "2007 | [MeSH] AUC-0.9098 F1-0.7401 ; [Eyes] AUC-0.9174 F1-0.7296 .\n",
            "2008 | [MeSH] AUC-0.9271 F1-0.7706 ; [Eyes] AUC-0.9168 F1-0.7286 .\n",
            "2009 | [MeSH] AUC-0.9137 F1-0.7382 ; [Eyes] AUC-0.9240 F1-0.7201 .\n",
            "2010 | [MeSH] AUC-0.9140 F1-0.7387 ; [Eyes] AUC-0.9261 F1-0.7198 .\n",
            "2011 | [MeSH] AUC-0.9286 F1-0.7680 ; [Eyes] AUC-0.9236 F1-0.7229 .\n",
            "2012 | [MeSH] AUC-0.9173 F1-0.7373 ; [Eyes] AUC-0.9281 F1-0.7160 .\n",
            "2013 | [MeSH] AUC-0.9116 F1-0.7426 ; [Eyes] AUC-0.9198 F1-0.7317 .\n",
            "2014 | [MeSH] AUC-0.9148 F1-0.7422 ; [Eyes] AUC-0.9213 F1-0.7321 .\n",
            "2015 | [MeSH] AUC-0.9145 F1-0.7452 ; [Eyes] AUC-0.9223 F1-0.7325 .\n",
            "2016 | [MeSH] AUC-0.9127 F1-0.7438 ; [Eyes] AUC-0.9236 F1-0.7275 .\n",
            "2017 | [MeSH] AUC-0.9121 F1-0.7424 ; [Eyes] AUC-0.9212 F1-0.7306 .\n",
            "2018 | [MeSH] AUC-0.9174 F1-0.7360 ; [Eyes] AUC-0.9276 F1-0.7194 .\n",
            "2019 | [MeSH] AUC-0.9118 F1-0.7354 ; [Eyes] AUC-0.9225 F1-0.7202 .\n",
            "2020 | [MeSH] AUC-0.9338 F1-0.7667 ; [Eyes] AUC-0.9298 F1-0.7106 .\n",
            "2021 | [MeSH] AUC-0.9120 F1-0.7235 ; [Eyes] AUC-0.9220 F1-0.7066 .\n",
            "2022 | [MeSH] AUC-0.9883 F1-0.9677 ; [Eyes] AUC-1.0000 F1-0.9333 .\n",
            "CPU times: user 43min 8s, sys: 1min 54s, total: 45min 2s\n",
            "Wall time: 46min 18s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "mesh_eval = []\n",
        "eyes_eval = []\n",
        "for year in range(2002,2022):\n",
        "    dataset = OncologyMeSH(f\"dataset/Oncology{year}\",year)\n",
        "    graph = dataset[0]\n",
        "    graph.x = graph.x.float()\n",
        "    graph = graph.to(device)\n",
        "    # graph.x = torch.eye(graph.x.size(0),dtype=torch.float)\n",
        "    split = T.RandomLinkSplit(\n",
        "        num_val=0.05,\n",
        "        num_test=0.1,\n",
        "        is_undirected=True,\n",
        "        add_negative_train_samples=False,\n",
        "        neg_sampling_ratio=1.0,\n",
        "    )\n",
        "    train_data, val_data, test_data = split(graph)\n",
        "    \n",
        "\n",
        "    model = Net(dataset.num_features, 512, 64).to(device)\n",
        "    # model = Net(graph.x.size(0),512,64).to(device)\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.005)\n",
        "    criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    model = train_link_predictor(model, train_data, val_data, optimizer, criterion, ckp_path=f'mesh{year}_checkpoint.pt')\n",
        "    model.load_state_dict(torch.load(f'mesh{year}_checkpoint.pt'))\n",
        "    test_eval = eval_link_predictor(model, test_data)\n",
        "    mesh_eval.append(test_eval)\n",
        "\n",
        "    print(f\"{year} | [MeSH] AUC-{test_eval[0]:.4f} F1-{test_eval[1]:.4f} ;\",end='')\n",
        "    del model,optimizer,criterion\n",
        "    torch.cuda.empty_cache()\n",
        "    # comparable \n",
        "    train_data.x = torch.eye(graph.x.size(0),dtype=torch.float).to(device)\n",
        "    val_data.x = torch.eye(graph.x.size(0),dtype=torch.float).to(device)\n",
        "    test_data.x = torch.eye(graph.x.size(0),dtype=torch.float).to(device)\n",
        "    model = Net(graph.x.size(0),512,64).to(device)\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.005)\n",
        "    criterion = torch.nn.BCEWithLogitsLoss()\n",
        "    model = train_link_predictor(model, train_data, val_data, optimizer, criterion,ckp_path=f'eyes{year}_checkpoint.pt')\n",
        "    \n",
        "    model.load_state_dict(torch.load(f'eyes{year}_checkpoint.pt'))\n",
        "    test_eval = eval_link_predictor(model, test_data)\n",
        "    eyes_eval.append(test_eval)\n",
        "\n",
        "    print(f\" [Eyes] AUC-{test_eval[0]:.4f} F1-{test_eval[1]:.4f} .\")\n",
        "    \n",
        "    del dataset,graph,model,optimizer,criterion,train_data, val_data, test_data\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IXMUl8x9Kqs"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(mesh_eval,index=range(2002,2023),columns=['auc','f1','accuracy','precision','recall']).to_csv('0507_mesh_eval.csv',sep=',',index=True)\n",
        "pd.DataFrame(eyes_eval,index=range(2002,2023),columns=['auc','f1','accuracy','precision','recall']).to_csv('0507_eyes_eval.csv',sep=',',index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4FyXeGlGUnoK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMNsKLdXj9by8JIPLXafe1b",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}