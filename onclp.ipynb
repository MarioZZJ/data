{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarioZZJ/data/blob/master/onclp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0QCgBMbX1X5",
        "outputId": "6777807a-f14a-4741-d473-3e3fab873f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KguGW7KuX_7z"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/dataset.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_sPYTsNZKg5",
        "outputId": "1bc00252-a73f-4d3e-c6c8-1795c3c18e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910476 sha256=3e5929ea1fc8d7b66c809811e10cfcdb8cab8a667326ebe27b6efb71d4f01eda\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "10DjOwBXxaPw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import InMemoryDataset,Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric import seed_everything\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch_geometric.utils import negative_sampling\n",
        "import numpy as np\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "36U8p-dnB12M"
      },
      "outputs": [],
      "source": [
        "def make_deterministic(random_seed = 711):\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(random_seed)\n",
        "    seed_everything(random_seed)\n",
        "\n",
        "make_deterministic(711)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l3iSMi3Qxy57"
      },
      "outputs": [],
      "source": [
        "class OncologyMeSH(InMemoryDataset):\n",
        "    def __init__(self, root, year,transform=None, pre_transform=None):\n",
        "        self.year = year\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return [f'oncology{self.year}.pt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QOXwHfkeYdGm"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0, path='checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        Early stopping 定义\n",
        "        \n",
        "        :param patience: 当验证集损失连续多少轮没有下降时停止训练\n",
        "        :param delta: 验证集损失的最小变化，当变化小于 delta 时认为模型没有明显提升\n",
        "        :param path: 记录模型权重的文件路径\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.counter = 0  # 记录验证集损失连续没有下降的轮数\n",
        "        self.best_score = None  # 记录最佳验证集损失\n",
        "        self.early_stop = False  # 是否停止训练\n",
        "        self.val_loss_min = np.Inf  # 记录最小验证集损失\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        \"\"\"\n",
        "        Early stopping 逻辑\n",
        "\n",
        "        :param val_loss: 当前轮次验证集损失\n",
        "        :param model: 当前轮次模型\n",
        "        :return: 如果需要停止训练，返回 True；否则返回 False\n",
        "        \"\"\"\n",
        "        if self.best_score is None:\n",
        "            self.best_score = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif val_loss > self.best_score - self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        \"\"\"\n",
        "        保存模型权重\n",
        "\n",
        "        :param val_loss: 当前轮次验证集损失\n",
        "        :param model: 当前轮次模型\n",
        "        \"\"\"\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "I-6xooJHyiID"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score, recall_score\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "\n",
        "def train_link_predictor(\n",
        "    model, train_data, val_data, optimizer, criterion, n_epochs=500, patience=20, delta=0.0003, ckp_path='checkpoint.pt'\n",
        "):\n",
        "    early_stopping = EarlyStopping(patience=patience, delta=delta, path=ckp_path)\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        z = model.encode(train_data.x, train_data.edge_index)\n",
        "\n",
        "        # sampling training negatives for every training epoch\n",
        "        neg_edge_index = negative_sampling(\n",
        "            edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
        "            num_neg_samples=train_data.edge_label_index.size(1), method='sparse',force_undirected=True)\n",
        "\n",
        "        edge_label_index = torch.cat(\n",
        "            [train_data.edge_label_index, neg_edge_index],\n",
        "            dim=-1,\n",
        "        )\n",
        "        edge_label = torch.cat([\n",
        "            train_data.edge_label,\n",
        "            train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
        "        ], dim=0)\n",
        "\n",
        "        out = model.decode(z, edge_label_index).view(-1)\n",
        "        loss = criterion(out, edge_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # val_auc = eval_link_predictor(model, val_data)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            z = model.encode(val_data.x, val_data.edge_index)\n",
        "            out = model.decode(z, val_data.edge_label_index).view(-1).sigmoid()\n",
        "            val_loss = criterion(out, val_data.edge_label)\n",
        "        val_auc = roc_auc_score(val_data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
        "\n",
        "        if early_stopping(val_loss, model):\n",
        "            break\n",
        "\n",
        "        # if epoch % 1 == 0:\n",
        "            # print(f\"Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_link_predictor(model, data):\n",
        "\n",
        "    model.eval()\n",
        "    z = model.encode(data.x, data.edge_index)\n",
        "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
        "\n",
        "    return [roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy()),\n",
        "            f1_score(data.edge_label.cpu().numpy(), out.cpu().numpy() > 0.5),\n",
        "            accuracy_score(data.edge_label.cpu().numpy(), out.cpu().numpy() > 0.5),\n",
        "            precision_score(data.edge_label.cpu().numpy(), out.cpu().numpy() > 0.5),\n",
        "            recall_score(data.edge_label.cpu().numpy(), out.cpu().numpy() > 0.5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eL8J70DFyqdU"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "    def decode(self, z, edge_label_index):\n",
        "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(\n",
        "            dim=-1\n",
        "        )  # product of a pair of nodes on each edge\n",
        "\n",
        "    def decode_all(self, z):\n",
        "        prob_adj = z @ z.t()\n",
        "        return (prob_adj > 0).nonzero(as_tuple=False).t()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6vmTrYQcyuMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a96a96d-5e06-48f2-c759-8b1739dc3b4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2002 | [MeSH] AUC-0.9233 F1-0.7730 ; [Eyes] AUC-0.9072 F1-0.7463 .\n",
            "2003 | [MeSH] AUC-0.9194 F1-0.7703 ; [Eyes] AUC-0.9036 F1-0.7474 .\n",
            "2004 | [MeSH] AUC-0.9227 F1-0.7709 ; [Eyes] AUC-0.9111 F1-0.7428 .\n",
            "2005 | [MeSH] AUC-0.9328 F1-0.7797 ; [Eyes] AUC-0.9151 F1-0.7356 .\n",
            "2006 | [MeSH] AUC-0.9259 F1-0.7717 ; [Eyes] AUC-0.9147 F1-0.7298 .\n",
            "2007 | [MeSH] AUC-0.9230 F1-0.7664 ; [Eyes] AUC-0.9147 F1-0.7321 .\n",
            "2008 | [MeSH] AUC-0.9342 F1-0.7760 ; [Eyes] AUC-0.9174 F1-0.7297 .\n",
            "2009 | [MeSH] AUC-0.9289 F1-0.7718 ; [Eyes] AUC-0.9225 F1-0.7273 .\n",
            "2010 | [MeSH] AUC-0.9304 F1-0.7682 ; [Eyes] AUC-0.9205 F1-0.7299 .\n",
            "2011 | [MeSH] AUC-0.9287 F1-0.7685 ; [Eyes] AUC-0.9224 F1-0.7264 .\n",
            "2012 | [MeSH] AUC-0.9303 F1-0.7686 ; [Eyes] AUC-0.9230 F1-0.7264 .\n",
            "2013 | [MeSH] AUC-0.9284 F1-0.7696 ; [Eyes] AUC-0.9213 F1-0.7307 .\n",
            "2014 | [MeSH] AUC-0.9300 F1-0.7710 ; [Eyes] AUC-0.9212 F1-0.7340 .\n",
            "2015 | [MeSH] AUC-0.9298 F1-0.7700 ; [Eyes] AUC-0.9199 F1-0.7355 .\n",
            "2016 | [MeSH] AUC-0.9137 F1-0.7436 ; [Eyes] AUC-0.9221 F1-0.7316 .\n",
            "2017 | [MeSH] AUC-0.9296 F1-0.7692 ; [Eyes] AUC-0.9216 F1-0.7312 .\n",
            "2018 | [MeSH] AUC-0.9309 F1-0.7690 ; [Eyes] AUC-0.9261 F1-0.7245 .\n",
            "2019 | [MeSH] AUC-0.9468 F1-0.7866 ; [Eyes] AUC-0.9223 F1-0.7201 .\n",
            "2020 | [MeSH] AUC-0.9178 F1-0.7322 ; [Eyes] AUC-0.9223 F1-0.7275 .\n",
            "2021 | [MeSH] AUC-0.9115 F1-0.7226 ; [Eyes] AUC-0.9159 F1-0.7179 .\n",
            "CPU times: user 59min 1s, sys: 2min 47s, total: 1h 1min 49s\n",
            "Wall time: 1h 3min 5s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "mesh_eval = []\n",
        "eyes_eval = []\n",
        "for year in range(2002,2022):\n",
        "    dataset = OncologyMeSH(f\"dataset/Oncology{year}\",year)\n",
        "    graph = dataset[0]\n",
        "    graph.x = graph.x.float()\n",
        "    graph = graph.to(device)\n",
        "    # graph.x = torch.eye(graph.x.size(0),dtype=torch.float)\n",
        "    split = T.RandomLinkSplit(\n",
        "        num_val=0.05,\n",
        "        num_test=0.1,\n",
        "        is_undirected=True,\n",
        "        add_negative_train_samples=False,\n",
        "        neg_sampling_ratio=1.0,\n",
        "    )\n",
        "    train_data, val_data, test_data = split(graph)\n",
        "    \n",
        "\n",
        "    model = Net(dataset.num_features, 400, 64).to(device)\n",
        "    # model = Net(graph.x.size(0),512,64).to(device)\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.005)\n",
        "    criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    model = train_link_predictor(model, train_data, val_data, optimizer, criterion, ckp_path=f'mesh{year}_checkpoint.pt',n_epochs=500, patience=20, delta=0.0001)\n",
        "    model.load_state_dict(torch.load(f'mesh{year}_checkpoint.pt'))\n",
        "    test_eval = eval_link_predictor(model, test_data)\n",
        "    mesh_eval.append(test_eval)\n",
        "\n",
        "    print(f\"{year} | [MeSH] AUC-{test_eval[0]:.4f} F1-{test_eval[1]:.4f} ;\",end='')\n",
        "    del model,optimizer,criterion\n",
        "    torch.cuda.empty_cache()\n",
        "    # comparable \n",
        "    mesh_num_features = graph.x.size(1)\n",
        "    mesh_num_samples = graph.x.size(0)\n",
        "    num_eyes = int(mesh_num_features // mesh_num_samples)\n",
        "    baseline_x = torch.concat([torch.eye(mesh_num_samples,dtype=torch.float) for i in range(num_eyes)],dim=1)\n",
        "    if mesh_num_features % mesh_num_samples != 0:\n",
        "      baseline_x = torch.concat([baseline_x, torch.zeros(mesh_num_samples, mesh_num_features % mesh_num_samples)],dim=1)\n",
        "    train_data.x = baseline_x.to(device)\n",
        "    val_data.x = baseline_x.to(device)\n",
        "    test_data.x = baseline_x.to(device)\n",
        "    model = Net(mesh_num_features,400,64).to(device)\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.005)\n",
        "    criterion = torch.nn.BCEWithLogitsLoss()\n",
        "    model = train_link_predictor(model, train_data, val_data, optimizer, criterion,ckp_path=f'eyes{year}_checkpoint.pt',n_epochs=500, patience=20, delta=0.0001)\n",
        "    \n",
        "    model.load_state_dict(torch.load(f'eyes{year}_checkpoint.pt'))\n",
        "    test_eval = eval_link_predictor(model, test_data)\n",
        "    eyes_eval.append(test_eval)\n",
        "\n",
        "    print(f\" [Eyes] AUC-{test_eval[0]:.4f} F1-{test_eval[1]:.4f} .\")\n",
        "    \n",
        "    del dataset,graph,model,optimizer,criterion,train_data, val_data, test_data\n",
        "    torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2IXMUl8x9Kqs"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(mesh_eval,index=range(2002,2022),columns=['auc','f1','accuracy','precision','recall']).to_csv('0508_gcn_mesh_eval.csv',sep=',',index=True)\n",
        "pd.DataFrame(eyes_eval,index=range(2002,2022),columns=['auc','f1','accuracy','precision','recall']).to_csv('0508_gcn_eyes_eval.csv',sep=',',index=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM28nmLfmoWy4U9gPAs7FDb",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}